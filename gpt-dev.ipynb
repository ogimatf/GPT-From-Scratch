{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skinut je shakespeare.txt fajl koji sadrzi sva dela Vilijama Sekspira. Ovo ce sluziti kao trening skup za pravljenje GPT modela koji generise tekst nalik na onaj iz dela ovog pisca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ucitavanje i pregled ulaza\n",
    "with open('shakespeare.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset in characters:  5447743\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of dataset in characters: \", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1609\n",
      "\n",
      "THE SONNETS\n",
      "\n",
      "by William Shakespeare\n",
      "\n",
      "\n",
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But as the riper should by time decease,\n",
      "  His tender heir might bear his memory:\n",
      "  But thou contracted to thine own bright eyes,\n",
      "  Feed'st thy light's flame with self-substantial fuel,\n",
      "  Making a famine where abundance lies,\n",
      "  Thy self thy foe, to thy sweet self too cruel:\n",
      "  Thou that art now the world's fresh ornament,\n",
      "  And only herald to the gaudy spring,\n",
      "  Within thine own bud buriest thy content,\n",
      "  And tender churl mak'st waste in niggarding:\n",
      "    Pity the world, or else this glutton be,\n",
      "    To eat the world's due, by the grave and thee.\n",
      "\n",
      "\n",
      "                     2\n",
      "  When forty winters shall besiege thy brow,\n",
      "  And dig deep trenches in thy beauty's field,\n",
      "  Thy youth's proud livery so gazed on now,\n",
      "  Will be a tattered weed of small worth held:  \n",
      "  Then being asked, where all thy beauty lies,\n",
      "  Where all the treasure of thy l\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !\"&'(),-.0123456789:;<>?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_`abcdefghijklmnopqrstuvwxyz|}\n",
      "84\n"
     ]
    }
   ],
   "source": [
    "#analiza karaktera\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizacija: konverzija niza karaktera u niz celih brojeva koji predstavljaju recnik mogucih elemenata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[81, 59, 73, 56, 77, 70, 1, 74, 77, 60, 75, 60]\n",
      "zdravo svete\n"
     ]
    }
   ],
   "source": [
    "#mapiranje karaktera u cele brojeve\n",
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "itos = {i:ch for i, ch in enumerate(chars)}\n",
    "\n",
    "encode = lambda s: [stoi[c] for c in s] #enkoder, uzima string, vraca listu celih brojeva\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) #dekoder: uzima listu celih brojeva, vraca string\n",
    "\n",
    "print(encode(\"zdravo svete\"))\n",
    "print(decode(encode(\"zdravo svete\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5447743]) torch.int64\n",
      "tensor([12, 17, 11, 20,  0,  0, 45, 33, 30,  1, 44, 40, 39, 39, 30, 45, 44,  0,\n",
      "         0, 57, 80,  1, 48, 64, 67, 67, 64, 56, 68,  1, 44, 63, 56, 66, 60, 74,\n",
      "        71, 60, 56, 73, 60,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 12,  0,  1,  1, 31, 73,\n",
      "        70, 68,  1, 61, 56, 64, 73, 60, 74, 75,  1, 58, 73, 60, 56, 75, 76, 73,\n",
      "        60, 74,  1, 78, 60,  1, 59, 60, 74, 64, 73, 60,  1, 64, 69, 58, 73, 60,\n",
      "        56, 74, 60,  8,  0,  1,  1, 45, 63, 56, 75,  1, 75, 63, 60, 73, 60, 57,\n",
      "        80,  1, 57, 60, 56, 76, 75, 80,  5, 74,  1, 73, 70, 74, 60,  1, 68, 64,\n",
      "        62, 63, 75,  1, 69, 60, 77, 60, 73,  1, 59, 64, 60,  8,  0,  1,  1, 27,\n",
      "        76, 75,  1, 56, 74,  1, 75, 63, 60,  1, 73, 64, 71, 60, 73,  1, 74, 63,\n",
      "        70, 76, 67, 59,  1, 57, 80,  1, 75, 64, 68, 60,  1, 59, 60, 58, 60, 56,\n",
      "        74, 60,  8,  0,  1,  1, 33, 64, 74,  1, 75, 60, 69, 59, 60, 73,  1, 63,\n",
      "        60, 64, 73,  1, 68, 64, 62, 63, 75,  1, 57, 60, 56, 73,  1, 63, 64, 74,\n",
      "         1, 68, 60, 68, 70, 73, 80, 21,  0,  1,  1, 27, 76, 75,  1, 75, 63, 70,\n",
      "        76,  1, 58, 70, 69, 75, 73, 56, 58, 75, 60, 59,  1, 75, 70,  1, 75, 63,\n",
      "        64, 69, 60,  1, 70, 78, 69,  1, 57, 73, 64, 62, 63, 75,  1, 60, 80, 60,\n",
      "        74,  8,  0,  1,  1, 31, 60, 60, 59,  5, 74, 75,  1, 75, 63, 80,  1, 67,\n",
      "        64, 62, 63, 75,  5, 74,  1, 61, 67, 56, 68, 60,  1, 78, 64, 75, 63,  1,\n",
      "        74, 60, 67, 61,  9, 74, 76, 57, 74, 75, 56, 69, 75, 64, 56, 67,  1, 61,\n",
      "        76, 60, 67,  8,  0,  1,  1, 38, 56, 66, 64, 69, 62,  1, 56,  1, 61, 56,\n",
      "        68, 64, 69, 60,  1, 78, 63, 60, 73, 60,  1, 56, 57, 76, 69, 59, 56, 69,\n",
      "        58, 60,  1, 67, 64, 60, 74,  8,  0,  1,  1, 45, 63, 80,  1, 74, 60, 67,\n",
      "        61,  1, 75, 63, 80,  1, 61, 70, 60,  8,  1, 75, 70,  1, 75, 63, 80,  1,\n",
      "        74, 78, 60, 60, 75,  1, 74, 60, 67, 61,  1, 75, 70, 70,  1, 58, 73, 76,\n",
      "        60, 67, 21,  0,  1,  1, 45, 63, 70, 76,  1, 75, 63, 56, 75,  1, 56, 73,\n",
      "        75,  1, 69, 70, 78,  1, 75, 63, 60,  1, 78, 70, 73, 67, 59,  5, 74,  1,\n",
      "        61, 73, 60, 74, 63,  1, 70, 73, 69, 56, 68, 60, 69, 75,  8,  0,  1,  1,\n",
      "        26, 69, 59,  1, 70, 69, 67, 80,  1, 63, 60, 73, 56, 67, 59,  1, 75, 70,\n",
      "         1, 75, 63, 60,  1, 62, 56, 76, 59, 80,  1, 74, 71, 73, 64, 69, 62,  8,\n",
      "         0,  1,  1, 48, 64, 75, 63, 64, 69,  1, 75, 63, 64, 69, 60,  1, 70, 78,\n",
      "        69,  1, 57, 76, 59,  1, 57, 76, 73, 64, 60, 74, 75,  1, 75, 63, 80,  1,\n",
      "        58, 70, 69, 75, 60, 69, 75,  8,  0,  1,  1, 26, 69, 59,  1, 75, 60, 69,\n",
      "        59, 60, 73,  1, 58, 63, 76, 73, 67,  1, 68, 56, 66,  5, 74, 75,  1, 78,\n",
      "        56, 74, 75, 60,  1, 64, 69,  1, 69, 64, 62, 62, 56, 73, 59, 64, 69, 62,\n",
      "        21,  0,  1,  1,  1,  1, 41, 64, 75, 80,  1, 75, 63, 60,  1, 78, 70, 73,\n",
      "        67, 59,  8,  1, 70, 73,  1, 60, 67, 74, 60,  1, 75, 63, 64, 74,  1, 62,\n",
      "        67, 76, 75, 75, 70, 69,  1, 57, 60,  8,  0,  1,  1,  1,  1, 45, 70,  1,\n",
      "        60, 56, 75,  1, 75, 63, 60,  1, 78, 70, 73, 67, 59,  5, 74,  1, 59, 76,\n",
      "        60,  8,  1, 57, 80,  1, 75, 63, 60,  1, 62, 73, 56, 77, 60,  1, 56, 69,\n",
      "        59,  1, 75, 63, 60, 60, 10,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 13,  0,  1,  1, 48,\n",
      "        63, 60, 69,  1, 61, 70, 73, 75, 80,  1, 78, 64, 69, 75, 60, 73, 74,  1,\n",
      "        74, 63, 56, 67, 67,  1, 57, 60, 74, 64, 60, 62, 60,  1, 75, 63, 80,  1,\n",
      "        57, 73, 70, 78,  8,  0,  1,  1, 26, 69, 59,  1, 59, 64, 62,  1, 59, 60,\n",
      "        60, 71,  1, 75, 73, 60, 69, 58, 63, 60, 74,  1, 64, 69,  1, 75, 63, 80,\n",
      "         1, 57, 60, 56, 76, 75, 80,  5, 74,  1, 61, 64, 60, 67, 59,  8,  0,  1,\n",
      "         1, 45, 63, 80,  1, 80, 70, 76, 75, 63,  5, 74,  1, 71, 73, 70, 76, 59,\n",
      "         1, 67, 64, 77, 60, 73, 80,  1, 74, 70,  1, 62, 56, 81, 60, 59,  1, 70,\n",
      "        69,  1, 69, 70, 78,  8,  0,  1,  1, 48, 64, 67, 67,  1, 57, 60,  1, 56,\n",
      "         1, 75, 56, 75, 75, 60, 73, 60, 59,  1, 78, 60, 60, 59,  1, 70, 61,  1,\n",
      "        74, 68, 56, 67, 67,  1, 78, 70, 73, 75, 63,  1, 63, 60, 67, 59, 21,  1,\n",
      "         1,  0,  1,  1, 45, 63, 60, 69,  1, 57, 60, 64, 69, 62,  1, 56, 74, 66,\n",
      "        60, 59,  8,  1, 78, 63, 60, 73, 60,  1, 56, 67, 67,  1, 75, 63, 80,  1,\n",
      "        57, 60, 56, 76, 75, 80,  1, 67, 64, 60, 74,  8,  0,  1,  1, 48, 63, 60,\n",
      "        73, 60,  1, 56, 67, 67,  1, 75, 63, 60,  1, 75, 73, 60, 56, 74, 76, 73,\n",
      "        60,  1, 70, 61,  1, 75, 63, 80,  1, 67])\n"
     ]
    }
   ],
   "source": [
    "#enkodiranje celog teksta uz pytorch\n",
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#podela trening podataka na skupove za treniranje i validaciju\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12, 17, 11, 20,  0,  0, 45, 33, 30])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trening se vrsi koristeci blokove teksta\n",
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ilustracija razumevanje izgleda skupa podataka.\n",
    "\n",
    "Trenira se model da predvidja sledece slovo (posle niza datih karaktera, verovatno ce se pojaviti ovaj kao sledeci).\n",
    "\n",
    "Hocemo da model predvidja sledeci karakter sa ogranicenim kontekstom koji moze biti i mali kao jedan karakter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kad je input tensor([12]) cilj je: 17\n",
      "Kad je input tensor([12, 17]) cilj je: 11\n",
      "Kad je input tensor([12, 17, 11]) cilj je: 20\n",
      "Kad je input tensor([12, 17, 11, 20]) cilj je: 0\n",
      "Kad je input tensor([12, 17, 11, 20,  0]) cilj je: 0\n",
      "Kad je input tensor([12, 17, 11, 20,  0,  0]) cilj je: 45\n",
      "Kad je input tensor([12, 17, 11, 20,  0,  0, 45]) cilj je: 33\n",
      "Kad je input tensor([12, 17, 11, 20,  0,  0, 45, 33]) cilj je: 30\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"Kad je input {context} cilj je: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ulazi:\n",
      "torch.Size([4, 8])\n",
      "tensor([[75, 56, 69, 75, 74,  2,  0,  1],\n",
      "        [ 1,  1,  1,  1, 32, 73, 60, 60],\n",
      "        [59,  1, 74, 75, 76, 68, 57, 67],\n",
      "        [80,  8,  0,  1,  1,  1,  1, 34]])\n",
      "Ciljevi:\n",
      "torch.Size([4, 8])\n",
      "tensor([[56, 69, 75, 74,  2,  0,  1,  1],\n",
      "        [ 1,  1,  1, 32, 73, 60, 60, 75],\n",
      "        [ 1, 74, 75, 76, 68, 57, 67, 60],\n",
      "        [ 8,  0,  1,  1,  1,  1, 34, 69]])\n",
      "----------\n",
      "Kada je ulaz [75], cilj je: 56\n",
      "Kada je ulaz [75, 56], cilj je: 69\n",
      "Kada je ulaz [75, 56, 69], cilj je: 75\n",
      "Kada je ulaz [75, 56, 69, 75], cilj je: 74\n",
      "Kada je ulaz [75, 56, 69, 75, 74], cilj je: 2\n",
      "Kada je ulaz [75, 56, 69, 75, 74, 2], cilj je: 0\n",
      "Kada je ulaz [75, 56, 69, 75, 74, 2, 0], cilj je: 1\n",
      "Kada je ulaz [75, 56, 69, 75, 74, 2, 0, 1], cilj je: 1\n",
      "Kada je ulaz [1], cilj je: 1\n",
      "Kada je ulaz [1, 1], cilj je: 1\n",
      "Kada je ulaz [1, 1, 1], cilj je: 1\n",
      "Kada je ulaz [1, 1, 1, 1], cilj je: 32\n",
      "Kada je ulaz [1, 1, 1, 1, 32], cilj je: 73\n",
      "Kada je ulaz [1, 1, 1, 1, 32, 73], cilj je: 60\n",
      "Kada je ulaz [1, 1, 1, 1, 32, 73, 60], cilj je: 60\n",
      "Kada je ulaz [1, 1, 1, 1, 32, 73, 60, 60], cilj je: 75\n",
      "Kada je ulaz [59], cilj je: 1\n",
      "Kada je ulaz [59, 1], cilj je: 74\n",
      "Kada je ulaz [59, 1, 74], cilj je: 75\n",
      "Kada je ulaz [59, 1, 74, 75], cilj je: 76\n",
      "Kada je ulaz [59, 1, 74, 75, 76], cilj je: 68\n",
      "Kada je ulaz [59, 1, 74, 75, 76, 68], cilj je: 57\n",
      "Kada je ulaz [59, 1, 74, 75, 76, 68, 57], cilj je: 67\n",
      "Kada je ulaz [59, 1, 74, 75, 76, 68, 57, 67], cilj je: 60\n",
      "Kada je ulaz [80], cilj je: 8\n",
      "Kada je ulaz [80, 8], cilj je: 0\n",
      "Kada je ulaz [80, 8, 0], cilj je: 1\n",
      "Kada je ulaz [80, 8, 0, 1], cilj je: 1\n",
      "Kada je ulaz [80, 8, 0, 1, 1], cilj je: 1\n",
      "Kada je ulaz [80, 8, 0, 1, 1, 1], cilj je: 1\n",
      "Kada je ulaz [80, 8, 0, 1, 1, 1, 1], cilj je: 34\n",
      "Kada je ulaz [80, 8, 0, 1, 1, 1, 1, 34], cilj je: 69\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1407)\n",
    "batch_size = 4 #koliko nezavisnih sekvenci se procesiraju od jednom\n",
    "block_size = 8 #najveca velicina konteksta za prdvidjanje\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print(\"Ulazi:\")\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print(\"Ciljevi:\")\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----------')\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "        print(f\"Kada je ulaz {context.tolist()}, cilj je: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 84])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(1407)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "        \n",
    "    def forward(self, idx, targets):\n",
    "        logits = self.token_embedding_table(idx)\n",
    "        return logits\n",
    "    \n",
    "m = BigramLanguageModel(vocab_size)\n",
    "out = m(xb, yb)\n",
    "print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
